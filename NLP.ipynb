{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\yicheng\\anaconda3\\envs\\gpu_env\\lib\\site-packages (3.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install protobuf\n",
    "# !pip install sentence-transformers\n",
    "# !pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \"Tell me more\"\n",
      "response: \"HUMAN: Tell me more\\nASSISTANT: The Human is a science fiction novel by author and futurist James P. Nestsus. The book was published in 1981 and tells the story of a man named John who is cryogenically frozen in the year 1981 and awakens in the year 2081.\\n\\nThe story is set in a future where humanity has colonized other planets and has developed advanced technology, including the ability to cryogenically freeze and revive people. The protagonist, John, is a scientist who is cryogenically frozen in order to preserve his knowledge and skills for the future.\\n\\nWhen John is revived in the year 2081,\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 問問題\\n\\n\\n# 檢查狀態\\nrel = client.checkModelState(modelName(modelName = \"vicuna\"))\\n\\n# 創建model\\nrel = client.createModelProc(modelConfig(modelName = \"vicuna\" , maxToken = 50))\\n\\n# 刪除model\\nrel = client.deleteModelProc(modelName(modelName = \"vicuna\"))\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"./model_grpc/\")\n",
    "from model_server_pb2 import ( modelRequest , modelResponse , modelName , modelInfo , modelConfig)\n",
    "# from model_server_pb2_grpc import *\n",
    "import grpc\n",
    "\n",
    "# connect server\n",
    "channel = grpc.insecure_channel(\"140.127.208.185:50051\")\n",
    "client = sendToModelStub(channel)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# 問問題\n",
    "user = 2\n",
    "request = modelRequest(user = user , modelName = \"vicuna\", prompt = \"Tell me more\")\n",
    "rel = client.getModelResponse(request)\n",
    "\n",
    "# 檢查狀態\n",
    "rel = client.checkModelState(modelName(modelName = \"vicuna\"))\n",
    "\n",
    "# 創建model\n",
    "rel = client.createModelProc(modelConfig(modelName = \"vicuna\" , maxToken = 50))\n",
    "\n",
    "# 刪除model\n",
    "rel = client.deleteModelProc(modelName(modelName = \"vicuna\"))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import bisect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read story\n",
    "#### Get high light and save it\n",
    "* high light 傳來會是一個有start idx 和 end idx的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find whether has highlight in this paragraph  \n",
    "def find_has_highlight(start_idx:int,end_idx:int,keys:list)->list:\n",
    "    \n",
    "    # save key of highlight\n",
    "    list_high_light = list()\n",
    "    # find start highlight ,lower_bound\n",
    "    idx= bisect.bisect_left(keys,start_idx)\n",
    "    \n",
    "    try:\n",
    "        # find others until greater than end_idx\n",
    "        for i in range(idx,len(keys)):\n",
    "            if keys[i] <= end_idx:\n",
    "                list_high_light.append(keys[i])\n",
    "    except:\n",
    "        # there isn't highlight in this paragraph\n",
    "        pass\n",
    "\n",
    "    return list_high_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification ,pipeline ,BartForConditionalGeneration\n",
    "\n",
    "model_paragraph_similarity = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "tokenizer_get_paragraph_name = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model_get_paragraph_name = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "\n",
    "tokenizer_summarize = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model_summarize = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def paragraph_similarity(model,paragraph1:str,paragraph2:str):\n",
    "    \n",
    "\n",
    "    sentences = [paragraph1,paragraph2]\n",
    "\n",
    "    # Compute the embeddings\n",
    "    embeddings = model.encode(sentences)\n",
    "\n",
    "    # Compute the cosine similarity between the embeddings\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = cosine_similarity(embeddings)\n",
    "    print(similarity[0][1])\n",
    "    return similarity[0][1]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(paragraph:str):\n",
    "    inputs = tokenizer_summarize(paragraph, max_length=1024, return_tensors=\"pt\",truncation=True)\n",
    "    # Generate Summary\n",
    "    summary_ids = model_summarize.generate(inputs[\"input_ids\"], num_beams=3, min_length=20, max_length=450)\n",
    "    summarize_content = tokenizer_summarize.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "    return summarize_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_paragraph_name(model,paragraph:str,threshold)->list():\n",
    "    \n",
    "\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer_get_paragraph_name)\n",
    "    ner_results = nlp(paragraph)\n",
    "\n",
    "    \n",
    "    table = [\"B-PER\",\"I-PER\"]\n",
    "    names = list()\n",
    "    \n",
    "    for ner in ner_results:\n",
    "        if ner[\"entity\"] in table and ner[\"score\"] >= threshold:\n",
    "            \n",
    "            if ner[\"word\"] not in names:\n",
    "                names.append(ner[\"word\"])\n",
    "    \n",
    "    if len(names) == 0 : return None\n",
    "    \n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{91: 275, 506: 662, 1427: 1575, 2157: 2304, 2333: 2589}\n",
      "The kids at school teased me and were cruel to me. I was 14 when the most popular girl at school, Jessica, poured juice on my head. Everyone laughed as I cried in the bathroom, ashamed.\n",
      "Mary put suspicious pills in Jessica's backpack the next day and called the police. Jessica was in shock when two police officers found the pills in her bag.\n",
      "I heard the news that the boy who kissed me at the party was in the hospital. Supposedly, someone pushed him as he went down the steps to the subway.\n",
      "The school bell rang and suddenly all the kids in the school were standing in the hallway laughing at me. I felt anger, standing naked and ashamed. \n",
      "She turned into a devil when I told her what had happened. I begged her not to do anything, but Mary didn't listen to me. She opened her backpack, took out her books, and lit them with a match. Within a minute, the fire started spreading through the school.\n"
     ]
    }
   ],
   "source": [
    "# Read story\n",
    "story_file_path = \"./story/content/using.txt\"\n",
    "with open(story_file_path,\"r\") as file :\n",
    "    # remove space and \"\\n\" of head and tail of paragraph \n",
    "    content = file.read().strip()\n",
    "file.close()\n",
    "\n",
    "\n",
    "# Read highlight\n",
    "highlight_file_path = \"./story/highlight/using.txt\"\n",
    "with open(highlight_file_path,\"r\") as file:\n",
    "    \n",
    "    dict_highlight=dict()\n",
    "    line = file.readline()\n",
    "    while line :\n",
    "        start_idx , end_idx = line.strip('\\n').split(\" \")\n",
    "        line = file.readline()\n",
    "        dict_highlight[int(start_idx)] = int(end_idx)\n",
    "\n",
    "# Sorted order of dict's key \n",
    "copy = dict_highlight.copy()\n",
    "keys = sorted(dict_highlight.keys())\n",
    "dict_highlight.clear()\n",
    "for key in keys:\n",
    "    dict_highlight[key] = copy[key]\n",
    "    \n",
    "print(dict_highlight)\n",
    "\n",
    "# Testing highlight \n",
    "for key in dict_highlight.keys():\n",
    "    str = content[key:dict_highlight[key]+1]\n",
    "    print(str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter \n",
    "\n",
    "# Each input size\n",
    "INPUT_SIZE = 512\n",
    "# Whether similarity\n",
    "THRESHOLD_SIMILARITY = 0.6\n",
    "# Whether similarity\n",
    "THRESHOLD_IS_NAME = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56692034\n",
      "Tina was 14 when the most popular girl at school, Jessica, poured juice on her head. When she returned to the classroom, she saw a new student, Mary, who told her she should take revenge.\n",
      "['The kids at school teased me and were cruel to me. I was 14 when the most popular girl at school, Jessica, poured juice on my head. Everyone laughed as I cried in the bathroom, ashamed.']\n",
      "['Tina', 'Jessica', 'Mary']\n",
      "1.0\n",
      "Mary put suspicious pills in Jessica's backpack the next day and called the police. Jessica was in shock when two police officers found the pills in her bag.\n",
      "[]\n",
      "['Mary', 'Jessica']\n",
      "When the boy asked if I wanted to kiss him, I blushed and ran away. I didn't think much of it, though, so I went to the couch, leaned back on it, and fell asleep. When I woke up in the morning, the boy approached me and kissed me. I was shocked. I decided to tell Mary about this. She was pissed, telling me not to worry and it wasn't my fault.\n",
      "[]\n",
      "['Mary']\n",
      "0.78247094\n",
      "The boy who kissed me at the party was in the hospital. Supposedly, someone pushed him as he went down the steps to the subway. Mary told me to calm down. She said the boy got what he deserved.\n",
      "[]\n",
      "['Mary']\n",
      "0.4330125\n",
      "\"I knew it was one of the mean girls doing a prank on me, but I had to do something about it,\" she says. \"I felt anger, standing naked and ashamed\"\n",
      "['The school bell rang and suddenly all the kids in the school were standing in the hallway laughing at me. I felt anger, standing naked and ashamed. ']\n",
      "None\n",
      "0.90902555\n",
      "I begged her not to do anything, but Mary didn't listen to me. She opened her backpack, took out her books, and lit them with a match. Within a minute, the fire started spreading through the school. Fortunately, firefighters arrived quickly and managed to put it out.\n",
      "[]\n",
      "['Mary']\n",
      "The police found a recording from a camera across from the school and played it. I was shocked when I saw myself on the tape taking books out of my backpack, burning them, and throwing them through the school door. A psychologist told me I was suffering from a multiple personality disorder.\n",
      "[]\n",
      "None\n",
      "\"She told me that I created a character that was the complete opposite of me and that I called her Mary. So, Mary never even existed except in my head,\" she said.\n",
      "[]\n",
      "['Mary']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_idx = 0\n",
    "# 上一個子段落\n",
    "last_sub_paragraph =\"\"\n",
    "while current_idx < len(content):\n",
    "    \n",
    "    # Find complete paragraph\n",
    "    end_idx = min(current_idx + INPUT_SIZE-1,len(content)-1)\n",
    "    end_idx = content.rfind('.',current_idx,end_idx+1)\n",
    "    \n",
    "    # Do processing \n",
    "\n",
    "    # get sub_paragraph\n",
    "    sub_paragraph = content[current_idx:end_idx+1]\n",
    "    # Highlight in the paragraph\n",
    "    list_has_highlight = find_has_highlight(start_idx=current_idx,end_idx=end_idx,keys=keys)\n",
    "    \n",
    "    this_paragraph_highlight = list()\n",
    "    has_highlight =True\n",
    "    try:\n",
    "        for i in list_has_highlight:\n",
    "            highlight_content = content[i:dict_highlight[i]+1]\n",
    "            this_paragraph_highlight.append(highlight_content)\n",
    "    except:\n",
    "        has_highlight = False\n",
    "    \n",
    "   \n",
    "    # 重點擷取\n",
    "    # 要換成重點擷取後\n",
    "    summarize_paragraph = summarize(sub_paragraph)\n",
    "    # 檢查重點中是否有包含highlight內容\n",
    "    if has_highlight:\n",
    "        for highlight in this_paragraph_highlight:\n",
    "            \n",
    "            # print(highlight)\n",
    "            # print(sub_paragraph)\n",
    "            # print(summarize_paragraph)\n",
    "            # print(\"!\")\n",
    "            \n",
    "            # 大於特定值就當作已經有提到，把highlight中刪除 \n",
    "            if paragraph_similarity(model = model_paragraph_similarity,paragraph1 = highlight,paragraph2 = summarize_paragraph) >= THRESHOLD_SIMILARITY:\n",
    "                this_paragraph_highlight.remove(highlight)\n",
    "\n",
    "    # 檢查是否有人名\n",
    "    paragraph_name = get_paragraph_name(model = model_get_paragraph_name,paragraph=summarize_paragraph,threshold=THRESHOLD_IS_NAME)\n",
    "    print(summarize_paragraph)\n",
    "    print(this_paragraph_highlight)\n",
    "    print(paragraph_name)\n",
    "    \n",
    "    # 確認是否有生成過\n",
    "    # 沒有就找特徵，QA問題，或是generation\n",
    "    # 臉部特徵+ 重點擷取直接畫\n",
    "    # \n",
    "\n",
    "\n",
    "    # next paragraph\n",
    "    last_sub_paragraph = sub_paragraph\n",
    "    current_idx = end_idx+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
