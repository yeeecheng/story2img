{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9323)\n"
     ]
    }
   ],
   "source": [
    "# 文句相似度 測試\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)])\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)[0]\n",
    "    return last_hidden_states[0][0]\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return torch.dot(a, b) / (torch.norm(a) * torch.norm(b))\n",
    "\n",
    "text1 = \"我\"\n",
    "text2 = \"他\"\n",
    "\n",
    "embedding1 = get_bert_embedding(text1)\n",
    "embedding2 = get_bert_embedding(text2)\n",
    "\n",
    "similarity = cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_Name:\n",
    "\n",
    "    def __init__(self,model=\"LTP/base1\",GPU=True):\n",
    "        self.ltp = LTP(\"LTP/base1\")\n",
    "        #ltp = LTP(path = \"LTP/base|LTP/small|LTP/tiny\")\n",
    "\n",
    "        # GPU \n",
    "        if GPU and torch.cuda.is_available():\n",
    "            self.ltp.to(\"cuda\")\n",
    "    \n",
    "    def get_name(self,text):\n",
    "        \n",
    "        # cws 分詞 : 將文句拆開\n",
    "        # pos 詞性標註 ， 將拆開的文句用詞性分類 ，名稱 : nh\n",
    "        # ner 命名實體\n",
    "        # 與文句的用詞也有關係\n",
    "        words = self.ltp.pipeline([text], tasks = [\"cws\",\"pos\",\"ner\",\"srl\",\"sdp\"])\n",
    "        names = []\n",
    "        for name in words[\"ner\"][0]:\n",
    "\n",
    "            if name[0] == \"Nh\" and name[1] not in names:\n",
    "                names.append(name[1])\n",
    "        maybe_names = self.find_noun(words[\"srl\"])\n",
    "        \n",
    "        for maybe_name in maybe_names:\n",
    "            if maybe_names[maybe_name] >= 1 :\n",
    "                if self.check_noun(maybe_name) and maybe_name not in names:\n",
    "                    names.append(maybe_name)\n",
    "\n",
    "        return names\n",
    "        \n",
    "    def find_noun(self,words):\n",
    "        \n",
    "        maybe_names = {}\n",
    "        for i in words[0]:\n",
    "            for j in i[\"arguments\"]:\n",
    "                if j[0] == \"A0\":\n",
    "                    try:\n",
    "                        maybe_names[j[1]]+=1\n",
    "                    except:\n",
    "                        maybe_names.setdefault(j[1],1)\n",
    "\n",
    "        return maybe_names\n",
    "\n",
    "    def check_noun(self,text):\n",
    "        \n",
    "        words = self.ltp.pipeline([text], tasks = [\"pos\"])\n",
    "        # print(text)\n",
    "        check_table = [\"nh\"]\n",
    "        for part_of_speech in words[\"pos\"]:\n",
    "            # print(part_of_speech)\n",
    "            if part_of_speech not in check_table:\n",
    "                return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['陸立鼎', '陸', '陸二娘']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "陸立鼎站起身來，正要入內與娘子商議如何應敵，陸二娘已走到廳上。陸立鼎將血手印指給她看，又說了墳破屍失之事。\n",
    "陸二娘皺眉道：「兩個孩子送到那裏去躲避？」陸立鼎指著牆上血手印道：「兩個孩子也在數內，這魔頭既按下了血手印，只怕輕易躲避不了。\n",
    "嘿，咱兩個枉自練了這些年武功，這人進出我家，我們沒半點知覺，這……這……」陸二娘望著白牆，抓住椅背，道：「為甚麼九個手印？咱們家裏可只有七口。」\n",
    "\"\"\"\n",
    "GN = Get_Name()\n",
    "GN.get_name(text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
